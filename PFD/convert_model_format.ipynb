{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert Model to ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd PFD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import cv2, numpy as np, matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.models import ResNet50_Weights\n",
    "from torchvision.models.detection import KeypointRCNN_ResNet50_FPN_Weights\n",
    "from torchvision.models.detection.rpn import AnchorGenerator\n",
    "from torchvision.transforms import functional as F\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import torchvision.transforms as T\n",
    "import onnx\n",
    "import onnxruntime as onnxrt\n",
    "from onnx_tf.backend import prepare\n",
    "from onnxruntime.quantization import quantize_dynamic, quantize_static, QuantType, QuantFormat\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(num_keypoints, weights_path=None):\n",
    "    \n",
    "    anchor_generator = AnchorGenerator(sizes=(32, 64, 128, 256, 512), aspect_ratios=(0.25, 0.5, 0.75, 1.0, 2.0, 3.0, 4.0))\n",
    "    model = torchvision.models.detection.keypointrcnn_resnet50_fpn(weights=None,\n",
    "                                                                   weights_backbone=ResNet50_Weights.DEFAULT,\n",
    "                                                                   num_keypoints=num_keypoints,\n",
    "                                                                   num_classes = 2, # Background is the first class, object is the second class\n",
    "                                                                   rpn_anchor_generator=anchor_generator, \n",
    "                                                                   min_size=512)\n",
    "\n",
    "    if weights_path:\n",
    "        state_dict = torch.load(weights_path)\n",
    "        model.load_state_dict(state_dict)        \n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "model = get_model(num_keypoints = 4, weights_path='./keypoint_model/weights/keypointsrcnn_weights.pth')\n",
    "model.to(device)\n",
    "print('done')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init random data to convert model\n",
    "frame_np_1 = np.random.rand(3, 512, 512)\n",
    "frame_np_1 = torch.FloatTensor(frame_np_1)\n",
    "frame_np_1.to(device)\n",
    "\n",
    "frame_np_2 = np.random.rand(3, 512, 512)\n",
    "frame_np_2 = torch.FloatTensor(frame_np_1)\n",
    "frame_np_2.to(device)\n",
    "\n",
    "x_reshaped = [frame_np_1, frame_np_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move model to cpu\n",
    "model.to('cpu')\n",
    "\n",
    "# convert pytorch model to onnx\n",
    "torch.onnx.export(\n",
    "    model, \n",
    "    [frame_np_1, frame_np_2], \n",
    "    \"./assets/keypoint_rcnn_min.onnx\", \n",
    "    input_names=['input_1'],\n",
    "    output_names=['boxes_1', 'labels_1', 'scores_1', 'keypoints_1', 'keypoints_scores_1'],\n",
    "    dynamic_axes={'input_1': {1: 'height', 2: 'width'}},\n",
    "    opset_version = 11\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quantize model for mobile use\n",
    "quantize_dynamic(\n",
    "    './assets/keypoint_rcnn_min.onnx', \n",
    "    './assets/keypoint_rcnn_min_quant.onnx',\n",
    "    weight_type=QuantType.QUInt8, \n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4d32610e65d0ba547d20b5ddccd11b31c7d91644470808fb362c82b58c120951"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
