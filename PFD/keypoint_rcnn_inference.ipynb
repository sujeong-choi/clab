{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import cv2, numpy as np, matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.models import ResNet50_Weights\n",
    "from torchvision.models.detection import KeypointRCNN_ResNet50_FPN_Weights\n",
    "from torchvision.models.detection.rpn import AnchorGenerator\n",
    "from torchvision.transforms import functional as F\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import torchvision.transforms as T\n",
    "from pytorch2keras.converter import pytorch_to_keras\n",
    "import onnx\n",
    "from onnx_tf.backend import prepare\n",
    "from torch.utils.mobile_optimizer import optimize_for_mobile\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(num_keypoints, weights_path=None):\n",
    "    \n",
    "    anchor_generator = AnchorGenerator(sizes=(32, 64, 128, 256, 512), aspect_ratios=(0.25, 0.5, 0.75, 1.0, 2.0, 3.0, 4.0))\n",
    "    model = torchvision.models.detection.keypointrcnn_resnet50_fpn(weights=None,\n",
    "                                                                   weights_backbone=ResNet50_Weights.DEFAULT,\n",
    "                                                                   num_keypoints=num_keypoints,\n",
    "                                                                   num_classes = 2, # Background is the first class, object is the second class\n",
    "                                                                   rpn_anchor_generator=anchor_generator)\n",
    "\n",
    "    if weights_path:\n",
    "        state_dict = torch.load(weights_path)\n",
    "        model.load_state_dict(state_dict)        \n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "model = get_model(num_keypoints = 4, weights_path='./assets/keypoint_model/weights/keypointsrcnn_weights 004.pth')\n",
    "model.to(device)\n",
    "print('done')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Live Frame filter Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_bbox_center(bbox):\n",
    "    # calculate center of bbox\n",
    "    bbox_width = abs(bbox[0] - bbox[2])\n",
    "    bbox_height = abs(bbox[1] - bbox[3])\n",
    "\n",
    "    return [bbox[0] + bbox_width / 2, bbox[1] + bbox_height / 2], bbox_width, bbox_height\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def live_frame_filter(keypoint, bbox):\n",
    "    filtered_keypoints = []\n",
    "    filtered_frames = []\n",
    "    # filter threshold\n",
    "    x_threshold = 0.5\n",
    "    y_threshold = 6\n",
    "\n",
    "    # calculate center of bbox\n",
    "    bbox_center, bbox_width, bbox_height = calculate_bbox_center(bbox)\n",
    "\n",
    "    # find left and right side coordinates\n",
    "    left_side_coordinates = []\n",
    "    right_side_coordinates = []\n",
    "\n",
    "    # Get the left and right side coordinates\n",
    "    for point in keypoint:\n",
    "        if bbox_center[0] < point[0]:\n",
    "            left_side_coordinates.append(point)\n",
    "        elif bbox_center[0] > point[0]:\n",
    "            right_side_coordinates.append(point)\n",
    "\n",
    "    if len(left_side_coordinates) != 2 or len(right_side_coordinates) != 2:\n",
    "        return False\n",
    "\n",
    "    # Get the top and bottom side coordinates\n",
    "    top_side_coordinates = []\n",
    "    bottom_side_coordinates = []\n",
    "\n",
    "    for point in keypoint:\n",
    "        if bbox_center[1] < point[1]:\n",
    "            top_side_coordinates.append(point)\n",
    "        elif bbox_center[1] > point[1]:\n",
    "            bottom_side_coordinates.append(point)\n",
    "    \n",
    "    if len(top_side_coordinates) != 2 or len(bottom_side_coordinates) != 2:\n",
    "        return False\n",
    "\n",
    "    # Extract the slope angles\n",
    "    left_side_slope = 0 if left_side_coordinates[0][0] - left_side_coordinates[1][0] == 0 else (left_side_coordinates[0][1] - left_side_coordinates[1][1]) / (left_side_coordinates[0][0] - left_side_coordinates[1][0])\n",
    "    right_side_slope = 0 if right_side_coordinates[0][0] - right_side_coordinates[1][0] == 0 else (right_side_coordinates[0][1] - right_side_coordinates[1][1]) / (right_side_coordinates[0][0] - right_side_coordinates[1][0])\n",
    "    top_side_slope = 0 if top_side_coordinates[1][0] - top_side_coordinates[0][0] == 0 else (top_side_coordinates[1][1] - top_side_coordinates[0][1]) / (top_side_coordinates[1][0] - top_side_coordinates[0][0])\n",
    "    bottom_side_slope = 0 if bottom_side_coordinates[1][0] - bottom_side_coordinates[0][0] == 0 else (bottom_side_coordinates[1][1] - bottom_side_coordinates[0][1]) / (bottom_side_coordinates[1][0] - bottom_side_coordinates[0][0])\n",
    "\n",
    "    diff_top_bottom = abs(top_side_slope - bottom_side_slope)\n",
    "    diff_left_right = abs(left_side_slope - right_side_slope)\n",
    "\n",
    "    if diff_top_bottom < x_threshold and diff_left_right < y_threshold:\n",
    "        return True\n",
    "        \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "from mediapipe.python.solutions import drawing_utils as mp_drawing\n",
    "from mediapipe.python.solutions import pose as mp_pose\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_hands = mp.solutions.hands\n",
    "\n",
    "bbox_buffer = 5\n",
    "\n",
    "def is_point_inside_rect(point, rect):\n",
    "    x, y = point\n",
    "    top_left_x, top_left_y, bottom_right_x, bottom_right_y = rect\n",
    "    rect_x = top_left_x - bbox_buffer\n",
    "    rect_y = top_left_y - bbox_buffer\n",
    "    rect_w = bottom_right_x - top_left_x + bbox_buffer\n",
    "    rect_h = bottom_right_y - top_left_y + bbox_buffer\n",
    "    return rect_x <= x <= rect_x + rect_w and rect_y <= y <= rect_y + rect_h\n",
    "\n",
    "def isHandInFrame(input_frame, bbox):\n",
    "    # Initialize fresh pose tracker and run it.\n",
    "      with mp_pose.Pose() as pose_tracker:\n",
    "        result = pose_tracker.process(image=input_frame)\n",
    "        pose_landmarks = result.pose_landmarks\n",
    "        \n",
    "        # Save landmarks.\n",
    "        if pose_landmarks is not None:\n",
    "            # Check the number of landmarks and take pose landmarks.\n",
    "            assert len(pose_landmarks.landmark) == 33, 'Unexpected number of predicted pose landmarks: {}'.format(len(pose_landmarks.landmark))\n",
    "\n",
    "            pose_landmarks = [[lmk.x, lmk.y, lmk.z] for lmk in pose_landmarks.landmark]\n",
    "\n",
    "            # only extract upper body\n",
    "            pose_landmarks = pose_landmarks[:25]\n",
    "\n",
    "            # Map pose landmarks from [0, 1] range to absolute coordinates to get\n",
    "            # correct aspect ratio.\n",
    "            frame_height, frame_width = input_frame.shape[:2]\n",
    "            pose_landmarks *= np.array([frame_width, frame_height, frame_width])\n",
    "\n",
    "            # check if pose is inside keypoint\n",
    "            for pose in pose_landmarks:\n",
    "                if not is_point_inside_rect(pose[:2], bbox):\n",
    "                    return False\n",
    "            return True\n",
    "        else:\n",
    "            return False"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run model on Live Camera or Video Recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frame capture rate in seconds\n",
    "capture_rate = 10\n",
    "\n",
    "# video file\n",
    "video_file = \"./assets/pfd_video_dataset/demo_0227.mp4\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on video recording \n",
    "Choose from:\n",
    "* Display video and draw over bounding box\n",
    "* Extract frames for further processing (saves more time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with displaying video\n",
    "frame_list = []\n",
    "keypoint_list = []\n",
    "bbox_list = []\n",
    "\n",
    "# Open the video file\n",
    "video = cv2.VideoCapture(video_file)\n",
    "\n",
    "# Check if video is opened successfully\n",
    "if not video.isOpened():\n",
    "    print(\"Error opening video file\")\n",
    "\n",
    "# Get the width and height of the video\n",
    "width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "# Set the desired width\n",
    "desired_width = 500\n",
    "\n",
    "# Calculate the aspect ratio\n",
    "aspect_ratio = height / width\n",
    "\n",
    "# Calculate the new height\n",
    "desired_height = int(desired_width * aspect_ratio)\n",
    "\n",
    "# Get the frames per second of the video\n",
    "fps = video.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "# Calculate the number of frames to skip\n",
    "skip_frames = int(fps * capture_rate)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display video and draw keypoints and bounding box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the counter for frames\n",
    "frame_count = 0\n",
    "\n",
    "# keypoint, bbox and frame lists \n",
    "keypoints_main = []\n",
    "bboxes_main = []\n",
    "\n",
    "# Read until video is completed\n",
    "while(video.isOpened()):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = video.read()\n",
    "    \n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    if frame_count % skip_frames == 0:\n",
    "        bboxes_main = []\n",
    "        keypoints_main = []\n",
    "\n",
    "        frame_np = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        frame_tensor = F.to_tensor(frame_np)\n",
    "        frame_tensor = frame_tensor.to(device)\n",
    "        \n",
    "        images = [frame_tensor]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            model.to(device)\n",
    "            model.eval()\n",
    "            output = model(images)\n",
    "        \n",
    "        frame_tensor = (images[0].permute(1,2,0).detach().cpu().numpy() * 255).astype(np.uint8)\n",
    "        scores = output[0]['scores'].detach().cpu().numpy()\n",
    "        \n",
    "        high_scores_idxs = np.where(scores > 0.8)[0].tolist() # Indexes of boxes with scores > 0.7\n",
    "        post_nms_idxs = torchvision.ops.nms(output[0]['boxes'][high_scores_idxs], output[0]['scores'][high_scores_idxs], 0.3).cpu().numpy() # Indexes of boxes left after applying NMS (iou_threshold=0.3)\n",
    "\n",
    "        keypoints = []\n",
    "        for kps in output[0]['keypoints'][high_scores_idxs][post_nms_idxs].detach().cpu().numpy():\n",
    "            keypoints.append([list(map(int, kp[:2])) for kp in kps])\n",
    "            \n",
    "        bboxes = []\n",
    "        for bbox in output[0]['boxes'][high_scores_idxs][post_nms_idxs].detach().cpu().numpy():\n",
    "            bboxes.append(list(map(int, bbox.tolist())))\n",
    "\n",
    "\n",
    "        #filter keypoints\n",
    "        if len(keypoints) != 0 and live_frame_filter(keypoints[0], bboxes[0]) and isHandInFrame(frame_np, bboxes[0]) == False:\n",
    "            if(len(keypoints) != 0):\n",
    "                keypoints_main = keypoints\n",
    "            \n",
    "            if(len(bboxes) != 0):\n",
    "                bboxes_main = bboxes\n",
    "\n",
    "        # add frame to to frame_list\n",
    "        frame_list.append(cv2.cvtColor(frame.copy(), cv2.COLOR_BGR2RGB))\n",
    "        keypoint_list.append(keypoints_main)\n",
    "        bbox_list.append(bboxes_main)\n",
    "\n",
    "    if(len(keypoints_main) != 0):\n",
    "        points = np.array(keypoints_main[0], np.int32)\n",
    "        points = points.reshape((-1, 1, 2))\n",
    "\n",
    "        # Draw a keypoints on the frame\n",
    "        # cv2.polylines(frame, [points], isClosed=True, color=(0, 0, 0), thickness=8)\n",
    "        for point in points:\n",
    "            center = (point[0][0], point[0][1])\n",
    "            radius = 15\n",
    "\n",
    "            # Draw the keypoints using the circle() function\n",
    "            cv2.circle(frame, center, radius, (0, 0, 255), -1)\n",
    "\n",
    "        if(len(bboxes_main) != 0):\n",
    "            # draw a bbox on the frame\n",
    "            cv2.rectangle(frame, (bboxes_main[0][0], bboxes_main[0][1]),  (bboxes_main[0][2], bboxes_main[0][3]), color=(0, 255, 0), thickness=8)\n",
    "\n",
    "    # Display the resulting frame\n",
    "    frame = cv2.resize(frame, (desired_width, desired_height), interpolation=cv2.INTER_AREA)\n",
    "    cv2.imshow('Frame', frame)\n",
    "    \n",
    "    # Press Q on keyboard to exit\n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "    frame_count = frame_count + 1\n",
    "# Release the video\n",
    "video.release()\n",
    "\n",
    "# Close all windows\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract frames and keypoints for further processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the total number of frames in the video\n",
    "total_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "fps = int(video.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "# keypoint, bbox and frame lists \n",
    "keypoints_main = []\n",
    "bboxes_main = []\n",
    "\n",
    "# Loop through the frames of the video\n",
    "for i in range(total_frames):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = video.read()\n",
    "\n",
    "    if i % skip_frames == 0:\n",
    "        bboxes_main = []\n",
    "        keypoints_main = []\n",
    "\n",
    "        frame_np = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)            \n",
    "        frame_tensor = F.to_tensor(frame_np)\n",
    "        frame_tensor = frame_tensor.to(device)\n",
    "\n",
    "        images = [frame_tensor]\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            model.to(device)\n",
    "            model.eval()\n",
    "            output = model(images)\n",
    "\n",
    "        frame_tensor = (images[0].permute(1,2,0).detach().cpu().numpy() * 255).astype(np.uint8)\n",
    "        scores = output[0]['scores'].detach().cpu().numpy()\n",
    "\n",
    "        high_scores_idxs = np.where(scores > 0.8)[0].tolist() # Indexes of boxes with scores > 0.7\n",
    "        post_nms_idxs = torchvision.ops.nms(output[0]['boxes'][high_scores_idxs], output[0]['scores'][high_scores_idxs], 0.3).cpu().numpy() # Indexes of boxes left after applying NMS (iou_threshold=0.3)\n",
    "\n",
    "        keypoints = []\n",
    "        for kps in output[0]['keypoints'][high_scores_idxs][post_nms_idxs].detach().cpu().numpy():\n",
    "            keypoints.append([list(map(int, kp[:2])) for kp in kps])\n",
    "            \n",
    "        bboxes = []\n",
    "        for bbox in output[0]['boxes'][high_scores_idxs][post_nms_idxs].detach().cpu().numpy():\n",
    "            bboxes.append(list(map(int, bbox.tolist())))\n",
    "\n",
    "        #filter keypoints\n",
    "        if len(keypoints) != 0 and live_frame_filter(keypoints[0], bboxes[0]) and isHandInFrame(frame_np, bboxes[0]) == False:\n",
    "            if(len(keypoints) != 0):\n",
    "                keypoints_main = keypoints\n",
    "            \n",
    "            if(len(bboxes) != 0):\n",
    "                bboxes_main = bboxes\n",
    "        \n",
    "        # add frame to to frame_list\n",
    "        if len(keypoints_main) > 0:\n",
    "            frame_list.append(frame_tensor)\n",
    "            keypoint_list.append([keypoints_main[0]])\n",
    "            bbox_list.append(bboxes)\n",
    "\n",
    "# Release the video\n",
    "video.release()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on live camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the counter for frames\n",
    "frame_count = 0\n",
    "\n",
    "# keypoint, bbox and frame lists \n",
    "keypoints_main = []\n",
    "bboxes_main = []\n",
    "\n",
    "# Create a VideoCapture object\n",
    "cap = cv2.VideoCapture(0) # 0 means the default camera\n",
    "\n",
    "while True:\n",
    "    # Read a frame from the video\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if int(time.time()) % capture_rate == 0:\n",
    "        frame_np = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        frame_tensor = F.to_tensor(frame_np)\n",
    "        frame_tensor = frame_tensor.to(device)\n",
    "        images = [frame_tensor]\n",
    "\n",
    "\n",
    "        with torch.no_grad():\n",
    "            model.to(device)\n",
    "            model.eval()\n",
    "            output = model(images)\n",
    "        \n",
    "        frame_tensor = (images[0].permute(1,2,0).detach().cpu().numpy() * 255).astype(np.uint8)\n",
    "        scores = output[0]['scores'].detach().cpu().numpy()\n",
    "        \n",
    "        high_scores_idxs = np.where(scores > 0.7)[0].tolist() # Indexes of boxes with scores > 0.7\n",
    "        post_nms_idxs = torchvision.ops.nms(output[0]['boxes'][high_scores_idxs], output[0]['scores'][high_scores_idxs], 0.3).cpu().numpy() # Indexes of boxes left after applying NMS (iou_threshold=0.3)\n",
    "\n",
    "        keypoints = []\n",
    "        for kps in output[0]['keypoints'][high_scores_idxs][post_nms_idxs].detach().cpu().numpy():\n",
    "            keypoints.append([list(map(int, kp[:2])) for kp in kps])\n",
    "            \n",
    "        bboxes = []\n",
    "        for bbox in output[0]['boxes'][high_scores_idxs][post_nms_idxs].detach().cpu().numpy():\n",
    "            bboxes.append(list(map(int, bbox.tolist())))\n",
    "    \n",
    "        if(len(keypoints) != 0):\n",
    "            print(keypoints)\n",
    "            keypoints_main = keypoints\n",
    "        \n",
    "        if(len(bboxes) != 0):\n",
    "            print(bboxes)\n",
    "            bboxes_main = bboxes\n",
    "\n",
    "        # add frame to to frame_list\n",
    "        frame_list.append(frame)\n",
    "        keypoint_list.append(keypoints_main)\n",
    "        bbox_list.append(bboxes_main)\n",
    "\n",
    "    if(len(keypoints_main) != 0):\n",
    "        points = np.array(keypoints_main, np.int32)\n",
    "        points = points.reshape((-1, 1, 2))\n",
    "\n",
    "        # Draw a keypoints on the frame\n",
    "        # cv2.polylines(frame, [points], isClosed=True, color=(0, 0, 0), thickness=8)\n",
    "        for point in points:\n",
    "            center = (point[0][0], point[0][1])\n",
    "            radius = 15\n",
    "\n",
    "            # Draw the keypoints using the circle() function\n",
    "            cv2.circle(frame, center, radius, (255, 0, 0), -1)\n",
    "\n",
    "    if(len(bboxes_main) != 0):\n",
    "        # draw a bbox on the frame\n",
    "        cv2.rectangle(frame, (bboxes_main[0][0], bboxes_main[0][1]),  (bboxes_main[0][2], bboxes_main[0][3]), color=(0, 255, 0), thickness=8)\n",
    "        \n",
    "    # Display the frame with the bounding box\n",
    "    cv2.imshow(\"Live Video with Bounding Box\", frame)\n",
    "\n",
    "    # `Exit the loop if the 'q' key is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "    frame_count = frame_count + 1\n",
    "\n",
    "# Release the video capture object\n",
    "cap.release()\n",
    "\n",
    "# Close all windows\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perspective Transformation and Timelapse"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perspective Transformation and Timelapse Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1021, 343]\n",
      "[962, 776]\n",
      "[1201, 857]\n",
      "[1287, 372]\n",
      "[1020, 352]\n",
      "[977, 781]\n",
      "[1200, 848]\n",
      "[1282, 372]\n",
      "[1018, 354]\n",
      "[971, 781]\n",
      "[1204, 847]\n",
      "[1293, 374]\n",
      "[1020, 357]\n",
      "[974, 783]\n",
      "[1195, 842]\n",
      "[1268, 375]\n",
      "[1019, 356]\n",
      "[973, 782]\n",
      "[1201, 835]\n",
      "[1268, 373]\n",
      "[1029, 360]\n",
      "[984, 793]\n",
      "[1196, 829]\n",
      "[1271, 378]\n",
      "[1033, 344]\n",
      "[979, 778]\n",
      "[1200, 818]\n",
      "[1287, 378]\n",
      "[1037, 357]\n",
      "[973, 780]\n",
      "[1203, 824]\n",
      "[1306, 378]\n",
      "[1028, 362]\n",
      "[940, 776]\n",
      "[1200, 819]\n",
      "[1291, 379]\n",
      "[1039, 359]\n",
      "[948, 776]\n",
      "[1200, 834]\n",
      "[1291, 380]\n",
      "[1036, 354]\n",
      "[979, 791]\n",
      "[1195, 824]\n",
      "[1271, 378]\n",
      "[1034, 346]\n",
      "[983, 796]\n",
      "[1199, 830]\n",
      "[1273, 377]\n",
      "[1039, 356]\n",
      "[981, 779]\n",
      "[1199, 822]\n",
      "[1276, 376]\n",
      "[1037, 365]\n",
      "[983, 790]\n",
      "[1206, 847]\n",
      "[1290, 382]\n",
      "[1039, 360]\n",
      "[978, 778]\n",
      "[1200, 818]\n",
      "[1286, 378]\n",
      "[1039, 360]\n",
      "[998, 785]\n",
      "[1195, 828]\n",
      "[1288, 380]\n",
      "[1042, 359]\n",
      "[989, 780]\n",
      "[1199, 825]\n",
      "[1275, 378]\n",
      "[1042, 346]\n",
      "[960, 787]\n",
      "[1192, 787]\n",
      "[1317, 379]\n",
      "[1044, 359]\n",
      "[986, 779]\n",
      "[1194, 820]\n",
      "[1317, 379]\n",
      "[1043, 358]\n",
      "[980, 782]\n",
      "[1194, 823]\n",
      "[1313, 381]\n",
      "[1044, 359]\n",
      "[978, 779]\n",
      "[1195, 843]\n",
      "[1292, 381]\n",
      "[1042, 356]\n",
      "[981, 780]\n",
      "[1194, 822]\n",
      "[1318, 377]\n",
      "[1043, 356]\n",
      "[984, 782]\n",
      "[1194, 808]\n",
      "[1320, 379]\n",
      "[1043, 359]\n",
      "[981, 780]\n",
      "[1194, 820]\n",
      "[1319, 379]\n",
      "[1043, 359]\n",
      "[981, 780]\n",
      "[1195, 816]\n",
      "[1323, 380]\n",
      "[1043, 359]\n",
      "[979, 778]\n",
      "[1194, 814]\n",
      "[1322, 379]\n",
      "[1044, 357]\n",
      "[978, 779]\n",
      "[1193, 812]\n",
      "[1323, 380]\n",
      "[1042, 357]\n",
      "[986, 780]\n",
      "[1196, 816]\n",
      "[1323, 377]\n",
      "[1042, 355]\n",
      "[1002, 784]\n",
      "[1195, 837]\n",
      "[1270, 380]\n",
      "[1042, 356]\n",
      "[980, 778]\n",
      "[1194, 812]\n",
      "[1323, 376]\n",
      "[1043, 357]\n",
      "[983, 781]\n",
      "[1196, 817]\n",
      "[1314, 377]\n",
      "[1043, 358]\n",
      "[982, 779]\n",
      "[1194, 815]\n",
      "[1320, 377]\n",
      "[1041, 357]\n",
      "[1003, 782]\n",
      "[1195, 835]\n",
      "[1271, 377]\n",
      "[1043, 359]\n",
      "[984, 778]\n",
      "[1194, 818]\n",
      "[1318, 379]\n",
      "[1042, 354]\n",
      "[985, 781]\n",
      "[1194, 822]\n",
      "[1313, 379]\n",
      "[1041, 357]\n",
      "[1006, 783]\n",
      "[1196, 837]\n",
      "[1266, 380]\n",
      "[1043, 357]\n",
      "[983, 780]\n",
      "[1197, 813]\n",
      "[1315, 376]\n",
      "[1044, 358]\n",
      "[991, 778]\n",
      "[1195, 800]\n",
      "[1324, 378]\n",
      "[1047, 350]\n",
      "[994, 781]\n",
      "[1198, 814]\n",
      "[1301, 382]\n",
      "[1043, 349]\n",
      "[943, 779]\n",
      "[1196, 796]\n",
      "[1315, 381]\n",
      "[1045, 359]\n",
      "[983, 781]\n",
      "[1200, 807]\n",
      "[1331, 381]\n",
      "[1046, 363]\n",
      "[983, 776]\n",
      "[1197, 794]\n",
      "[1322, 383]\n",
      "[1046, 347]\n",
      "[984, 782]\n",
      "[1200, 808]\n",
      "[1331, 382]\n",
      "[1041, 372]\n",
      "[951, 706]\n",
      "[1182, 761]\n",
      "[1284, 380]\n",
      "[1050, 358]\n",
      "[996, 779]\n",
      "[1200, 816]\n",
      "[1307, 382]\n",
      "[1049, 356]\n",
      "[996, 782]\n",
      "[1199, 817]\n",
      "[1302, 381]\n",
      "[1048, 356]\n",
      "[999, 780]\n",
      "[1201, 820]\n",
      "[1301, 381]\n",
      "[1048, 367]\n",
      "[985, 794]\n",
      "[1196, 794]\n",
      "[1320, 384]\n",
      "[1048, 360]\n",
      "[984, 780]\n",
      "[1199, 826]\n",
      "[1300, 381]\n",
      "[1047, 363]\n",
      "[981, 786]\n",
      "[1199, 805]\n",
      "[1312, 384]\n",
      "[1048, 360]\n",
      "[985, 776]\n",
      "[1199, 817]\n",
      "[1303, 380]\n",
      "[1048, 367]\n",
      "[972, 769]\n",
      "[1195, 769]\n",
      "[1324, 383]\n",
      "[1047, 363]\n",
      "[975, 785]\n",
      "[1200, 828]\n",
      "[1285, 382]\n",
      "[1047, 369]\n",
      "[968, 787]\n",
      "[1199, 811]\n",
      "[1317, 385]\n",
      "[1047, 360]\n",
      "[971, 789]\n",
      "[1195, 789]\n",
      "[1332, 382]\n",
      "[1047, 356]\n",
      "[970, 787]\n",
      "[1198, 810]\n",
      "[1304, 380]\n",
      "[1050, 357]\n",
      "[980, 789]\n",
      "[1198, 829]\n",
      "[1285, 380]\n",
      "[1048, 351]\n",
      "[968, 786]\n",
      "[1199, 828]\n",
      "[1300, 383]\n",
      "[1049, 358]\n",
      "[963, 774]\n",
      "[1200, 843]\n",
      "[1289, 381]\n",
      "[1050, 351]\n",
      "[965, 780]\n",
      "[1199, 819]\n",
      "[1307, 382]\n",
      "[1046, 350]\n",
      "[980, 794]\n",
      "[1198, 812]\n",
      "[1309, 381]\n",
      "[1045, 356]\n",
      "[976, 785]\n",
      "[1196, 804]\n",
      "[1306, 379]\n",
      "[1048, 357]\n",
      "[960, 782]\n",
      "[1196, 805]\n",
      "[1306, 380]\n",
      "[1049, 362]\n",
      "[979, 784]\n",
      "[1196, 808]\n",
      "[1287, 383]\n",
      "[1047, 364]\n",
      "[968, 783]\n",
      "[1196, 801]\n",
      "[1310, 382]\n",
      "[1049, 350]\n",
      "[979, 770]\n",
      "[1197, 819]\n",
      "[1291, 382]\n",
      "[1049, 356]\n",
      "[980, 780]\n",
      "[1199, 834]\n",
      "[1284, 382]\n",
      "[1050, 389]\n",
      "[976, 771]\n",
      "[1191, 771]\n",
      "[1325, 389]\n",
      "[1045, 379]\n",
      "[958, 782]\n",
      "[1190, 782]\n",
      "[1328, 379]\n",
      "[1050, 360]\n",
      "[969, 772]\n",
      "[1199, 843]\n",
      "[1289, 383]\n",
      "[1051, 353]\n",
      "[964, 780]\n",
      "[1197, 831]\n",
      "[1307, 379]\n",
      "[1049, 361]\n",
      "[969, 774]\n",
      "[1199, 813]\n",
      "[1314, 383]\n",
      "[1049, 355]\n",
      "[975, 779]\n",
      "[1200, 825]\n",
      "[1301, 381]\n",
      "[1049, 350]\n",
      "[984, 687]\n",
      "[1197, 813]\n",
      "[1288, 383]\n",
      "[1052, 373]\n",
      "[961, 770]\n",
      "[1195, 792]\n",
      "[1328, 373]\n",
      "[1051, 356]\n",
      "[969, 771]\n",
      "[1196, 811]\n",
      "[1295, 380]\n"
     ]
    }
   ],
   "source": [
    "# Calculate the frame rate\n",
    "num_frames = len(frame_list)\n",
    "timelapse_length = num_frames / 2\n",
    "frame_rate = int(num_frames / timelapse_length)\n",
    "\n",
    "#\n",
    "\n",
    "# previous frame for blending\n",
    "prev_frame = []\n",
    "# keypoint = keypoint_list[0][0]\n",
    "# bbox = bbox_list[0][0]\n",
    "\n",
    "bbox_center, bbox_width, bbox_height = calculate_bbox_center(bbox)\n",
    "\n",
    "#  Define the codec and create a video writer\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"MP4V\" )\n",
    "out = cv2.VideoWriter(\"timelapse.mp4\", fourcc, frame_rate, (bbox_width, bbox_height))\n",
    "\n",
    "\n",
    "for count, frame in enumerate(frame_list):\n",
    "    keypoint = keypoint_list[count][0]\n",
    "    bbox = bbox_list[count][0]\n",
    "\n",
    "    # pt1 => (top_left, top_right, bottom_left, bottom_right)\n",
    "    top_left = []\n",
    "    top_right = []\n",
    "    bottom_left = []\n",
    "    bottom_right = []\n",
    "\n",
    "    for kp in keypoint:\n",
    "        print(kp)\n",
    "        if kp[0] < bbox_center[0] and kp[1] < bbox_center[1]:\n",
    "            top_left = kp\n",
    "        elif kp[0] > bbox_center[0] and kp[1] > bbox_center[1]:\n",
    "            bottom_right = kp\n",
    "        elif kp[0] < bbox_center[0] and kp[1] > bbox_center[1]:\n",
    "            top_right = kp\n",
    "        elif kp[0] > bbox_center[0] and kp[1] < bbox_center[1]:\n",
    "            bottom_left = kp\n",
    "\n",
    "    pt1 = np.float32([top_left, bottom_left, top_right, bottom_right])\n",
    "    pt2 = np.float32([[0,0],[bbox_width, 0], [0, bbox_height], [bbox_width, bbox_height]])\n",
    "    M = cv2.getPerspectiveTransform(pt1,pt2)\n",
    "\n",
    "    # Perform the transformation\n",
    "    warped_image = cv2.warpPerspective(frame, M, (bbox_width, bbox_height))\n",
    "    warped_image = cv2.cvtColor(warped_image,cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # blend frames together for better transition\n",
    "    if count != 0:\n",
    "        blended = cv2.addWeighted(prev_frame, 0.1, warped_image, 0.9, 0)\n",
    "    else:\n",
    "        blended = warped_image\n",
    "    prev_frame = warped_image\n",
    "\n",
    "    out.write(blended)\n",
    "\n",
    "# Release the video writer\n",
    "out.release()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Model for Android"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = T.Resize(size = (512, 512))\n",
    "\n",
    "frame_1 = transform(F.to_tensor(frame_list[0]))\n",
    "frame_2 = transform(F.to_tensor(frame_list[1]))\n",
    "\n",
    "x = [frame_1, frame_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frame_np_1 = frame_list[0]\n",
    "# frame_np_1 = np.resize(frame_np_1, (3, 512, 512))\n",
    "frame_np_1 = np.random.rand(3, 512, 512)\n",
    "\n",
    "frame_np_1 = torch.FloatTensor(frame_np_1)\n",
    "frame_np_1.to(device)\n",
    "\n",
    "# frame_np_2 = frame_list[1]\n",
    "# frame_np_2 = np.resize(frame_np_1, (3, 512, 512))\n",
    "frame_np_2 = np.random.rand(3, 512, 512)\n",
    "\n",
    "frame_np_2 = torch.FloatTensor(frame_np_1)\n",
    "frame_np_2.to(device)\n",
    "\n",
    "x_reshaped = [frame_np_1, frame_np_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch2keras:Converter is called.\n",
      "WARNING:pytorch2keras:Custom shapes isn't supported now.\n",
      "DEBUG:pytorch2keras:Input_names:\n",
      "DEBUG:pytorch2keras:['input_0']\n",
      "DEBUG:pytorch2keras:Output_names:\n",
      "DEBUG:pytorch2keras:['output_0', 'output_1']\n",
      "c:\\Users\\Hisku\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\functional.py:3908: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  (torch.floor((input.size(i + 2).float() * torch.tensor(scale_factors[i], dtype=torch.float32)).float()))\n",
      "c:\\Users\\Hisku\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torchvision\\ops\\boxes.py:157: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  boxes_x = torch.min(boxes_x, torch.tensor(width, dtype=boxes.dtype, device=boxes.device))\n",
      "c:\\Users\\Hisku\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torchvision\\ops\\boxes.py:159: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  boxes_y = torch.min(boxes_y, torch.tensor(height, dtype=boxes.dtype, device=boxes.device))\n",
      "c:\\Users\\Hisku\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\__init__.py:853: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert condition, message\n",
      "c:\\Users\\Hisku\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torchvision\\models\\detection\\transform.py:298: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(s, dtype=torch.float32, device=boxes.device)\n",
      "c:\\Users\\Hisku\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torchvision\\models\\detection\\transform.py:299: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  / torch.tensor(s_orig, dtype=torch.float32, device=boxes.device)\n",
      "c:\\Users\\Hisku\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torchvision\\models\\detection\\transform.py:280: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(s, dtype=torch.float32, device=keypoints.device)\n",
      "c:\\Users\\Hisku\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torchvision\\models\\detection\\transform.py:281: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  / torch.tensor(s_orig, dtype=torch.float32, device=keypoints.device)\n",
      "c:\\Users\\Hisku\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\onnx\\_internal\\jit_utils.py:258: UserWarning: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\jit\\passes\\onnx\\shape_type_inference.cpp:1888.)\n",
      "  _C._jit_pass_onnx_node_shape_type_inference(node, params_dict, opset_version)\n",
      "c:\\Users\\Hisku\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\onnx\\symbolic_opset9.py:5408: UserWarning: Exporting aten::index operator of advanced indexing in opset 14 is achieved by combination of multiple ONNX operators, including Reshape, Transpose, Concat, and Gather. If indices include negative values, the exported graph will produce incorrect results.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Hisku\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\onnx\\utils.py:687: UserWarning: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\jit\\passes\\onnx\\shape_type_inference.cpp:1888.)\n",
      "  _C._jit_pass_onnx_graph_shape_type_inference(\n",
      "c:\\Users\\Hisku\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\onnx\\utils.py:1178: UserWarning: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\jit\\passes\\onnx\\shape_type_inference.cpp:1888.)\n",
      "  _C._jit_pass_onnx_graph_shape_type_inference(\n",
      "INFO:onnx2keras:Converter is called.\n",
      "DEBUG:onnx2keras:List input shapes:\n",
      "DEBUG:onnx2keras:[(3, 512, 512)]\n",
      "DEBUG:onnx2keras:List inputs:\n",
      "DEBUG:onnx2keras:Input 0 -> input_0.\n",
      "DEBUG:onnx2keras:Input 1 -> image.5.\n",
      "DEBUG:onnx2keras:List outputs:\n",
      "DEBUG:onnx2keras:Output 0 -> output_0.\n",
      "DEBUG:onnx2keras:Output 1 -> output_1.\n",
      "DEBUG:onnx2keras:Output 2 -> 3567.\n",
      "DEBUG:onnx2keras:Output 3 -> 4345.\n",
      "DEBUG:onnx2keras:Output 4 -> end_scores.7.\n",
      "DEBUG:onnx2keras:Output 5 -> 4375.\n",
      "DEBUG:onnx2keras:Output 6 -> 3701.\n",
      "DEBUG:onnx2keras:Output 7 -> 3700.\n",
      "DEBUG:onnx2keras:Output 8 -> 4387.\n",
      "DEBUG:onnx2keras:Output 9 -> end_scores.21.\n",
      "DEBUG:onnx2keras:Gathering weights to dictionary.\n",
      "DEBUG:onnx2keras:Found weight backbone.body.conv1.weight with shape (64, 3, 7, 7).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.bn1.weight with shape (64,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.bn1.bias with shape (64,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.bn1.running_mean with shape (64,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.bn1.running_var with shape (64,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer1.0.conv1.weight with shape (64, 64, 1, 1).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer1.0.bn1.weight with shape (64,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer1.0.bn1.bias with shape (64,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer1.0.bn1.running_mean with shape (64,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer1.0.bn1.running_var with shape (64,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer1.0.conv2.weight with shape (64, 64, 3, 3).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer1.0.bn2.weight with shape (64,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer1.0.bn2.bias with shape (64,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer1.0.bn2.running_mean with shape (64,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer1.0.bn2.running_var with shape (64,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer1.0.conv3.weight with shape (256, 64, 1, 1).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer1.0.bn3.weight with shape (256,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer1.0.bn3.bias with shape (256,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer1.0.bn3.running_mean with shape (256,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer1.0.bn3.running_var with shape (256,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer1.0.downsample.0.weight with shape (256, 64, 1, 1).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer1.0.downsample.1.weight with shape (256,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer1.0.downsample.1.running_mean with shape (256,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer1.0.downsample.1.running_var with shape (256,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer1.1.conv1.weight with shape (64, 256, 1, 1).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer1.1.bn1.weight with shape (64,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer1.1.bn1.bias with shape (64,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer1.1.bn1.running_mean with shape (64,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer1.1.bn1.running_var with shape (64,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer1.1.conv2.weight with shape (64, 64, 3, 3).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer1.1.bn2.weight with shape (64,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer1.1.bn2.bias with shape (64,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer1.1.bn2.running_mean with shape (64,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer1.1.bn2.running_var with shape (64,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer1.1.conv3.weight with shape (256, 64, 1, 1).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer1.1.bn3.weight with shape (256,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer1.1.bn3.bias with shape (256,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer1.1.bn3.running_mean with shape (256,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer1.1.bn3.running_var with shape (256,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer1.2.conv1.weight with shape (64, 256, 1, 1).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer1.2.bn1.weight with shape (64,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer1.2.bn1.bias with shape (64,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer1.2.bn1.running_mean with shape (64,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer1.2.bn1.running_var with shape (64,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer1.2.conv2.weight with shape (64, 64, 3, 3).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer1.2.bn2.weight with shape (64,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer1.2.bn2.bias with shape (64,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer1.2.bn2.running_mean with shape (64,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer1.2.bn2.running_var with shape (64,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer1.2.conv3.weight with shape (256, 64, 1, 1).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer1.2.bn3.weight with shape (256,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer1.2.bn3.bias with shape (256,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer1.2.bn3.running_mean with shape (256,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer1.2.bn3.running_var with shape (256,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer2.0.conv1.weight with shape (128, 256, 1, 1).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer2.0.bn1.weight with shape (128,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer2.0.bn1.bias with shape (128,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer2.0.bn1.running_mean with shape (128,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer2.0.bn1.running_var with shape (128,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer2.0.conv2.weight with shape (128, 128, 3, 3).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer2.0.bn2.weight with shape (128,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer2.0.bn2.bias with shape (128,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer2.0.bn2.running_mean with shape (128,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer2.0.bn2.running_var with shape (128,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer2.0.conv3.weight with shape (512, 128, 1, 1).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer2.0.bn3.weight with shape (512,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer2.0.bn3.bias with shape (512,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer2.0.bn3.running_mean with shape (512,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer2.0.bn3.running_var with shape (512,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer2.0.downsample.0.weight with shape (512, 256, 1, 1).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer2.0.downsample.1.weight with shape (512,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer2.0.downsample.1.running_mean with shape (512,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer2.0.downsample.1.running_var with shape (512,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer2.1.conv1.weight with shape (128, 512, 1, 1).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer2.1.bn1.weight with shape (128,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer2.1.bn1.bias with shape (128,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer2.1.bn1.running_mean with shape (128,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer2.1.bn1.running_var with shape (128,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer2.1.conv2.weight with shape (128, 128, 3, 3).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer2.1.bn2.weight with shape (128,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer2.1.bn2.bias with shape (128,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer2.1.bn2.running_mean with shape (128,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer2.1.bn2.running_var with shape (128,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer2.1.conv3.weight with shape (512, 128, 1, 1).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer2.1.bn3.weight with shape (512,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer2.1.bn3.bias with shape (512,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer2.1.bn3.running_mean with shape (512,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer2.1.bn3.running_var with shape (512,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer2.2.conv1.weight with shape (128, 512, 1, 1).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer2.2.bn1.weight with shape (128,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer2.2.bn1.bias with shape (128,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer2.2.bn1.running_mean with shape (128,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer2.2.bn1.running_var with shape (128,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer2.2.conv2.weight with shape (128, 128, 3, 3).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer2.2.bn2.weight with shape (128,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer2.2.bn2.bias with shape (128,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer2.2.bn2.running_mean with shape (128,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer2.2.bn2.running_var with shape (128,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer2.2.conv3.weight with shape (512, 128, 1, 1).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer2.2.bn3.weight with shape (512,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer2.2.bn3.bias with shape (512,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer2.2.bn3.running_mean with shape (512,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer2.2.bn3.running_var with shape (512,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer2.3.conv1.weight with shape (128, 512, 1, 1).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer2.3.bn1.weight with shape (128,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer2.3.bn1.bias with shape (128,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer2.3.bn1.running_mean with shape (128,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer2.3.bn1.running_var with shape (128,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer2.3.conv2.weight with shape (128, 128, 3, 3).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer2.3.bn2.weight with shape (128,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer2.3.bn2.bias with shape (128,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer2.3.bn2.running_mean with shape (128,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer2.3.bn2.running_var with shape (128,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer2.3.conv3.weight with shape (512, 128, 1, 1).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer2.3.bn3.weight with shape (512,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer2.3.bn3.bias with shape (512,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer2.3.bn3.running_mean with shape (512,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer2.3.bn3.running_var with shape (512,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer3.0.conv1.weight with shape (256, 512, 1, 1).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer3.0.bn1.weight with shape (256,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer3.0.bn1.bias with shape (256,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer3.0.bn1.running_mean with shape (256,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer3.0.bn1.running_var with shape (256,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer3.0.conv2.weight with shape (256, 256, 3, 3).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer3.0.bn2.weight with shape (256,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer3.0.bn2.bias with shape (256,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer3.0.bn2.running_mean with shape (256,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer3.0.bn2.running_var with shape (256,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer3.0.conv3.weight with shape (1024, 256, 1, 1).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer3.0.bn3.weight with shape (1024,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer3.0.bn3.bias with shape (1024,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer3.0.bn3.running_mean with shape (1024,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer3.0.bn3.running_var with shape (1024,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer3.0.downsample.0.weight with shape (1024, 512, 1, 1).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer3.0.downsample.1.weight with shape (1024,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer3.0.downsample.1.running_mean with shape (1024,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer3.0.downsample.1.running_var with shape (1024,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer3.1.conv1.weight with shape (256, 1024, 1, 1).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer3.1.bn1.weight with shape (256,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer3.1.bn1.bias with shape (256,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer3.1.bn1.running_mean with shape (256,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer3.1.bn1.running_var with shape (256,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer3.1.conv2.weight with shape (256, 256, 3, 3).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer3.1.bn2.weight with shape (256,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer3.1.bn2.bias with shape (256,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer3.1.bn2.running_mean with shape (256,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer3.1.bn2.running_var with shape (256,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer3.1.conv3.weight with shape (1024, 256, 1, 1).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer3.1.bn3.weight with shape (1024,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer3.1.bn3.bias with shape (1024,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer3.1.bn3.running_mean with shape (1024,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer3.1.bn3.running_var with shape (1024,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer3.2.conv1.weight with shape (256, 1024, 1, 1).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer3.2.bn1.weight with shape (256,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer3.2.bn1.bias with shape (256,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer3.2.bn1.running_mean with shape (256,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer3.2.bn1.running_var with shape (256,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer3.2.conv2.weight with shape (256, 256, 3, 3).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer3.2.bn2.weight with shape (256,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer3.2.bn2.bias with shape (256,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer3.2.bn2.running_mean with shape (256,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer3.2.bn2.running_var with shape (256,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer3.2.conv3.weight with shape (1024, 256, 1, 1).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer3.2.bn3.weight with shape (1024,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer3.2.bn3.bias with shape (1024,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer3.2.bn3.running_mean with shape (1024,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer3.2.bn3.running_var with shape (1024,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer3.3.conv1.weight with shape (256, 1024, 1, 1).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer3.3.bn1.weight with shape (256,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer3.3.bn1.bias with shape (256,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer3.3.bn1.running_mean with shape (256,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer3.3.bn1.running_var with shape (256,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer3.3.conv2.weight with shape (256, 256, 3, 3).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer3.3.bn2.weight with shape (256,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer3.3.bn2.bias with shape (256,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer3.3.bn2.running_mean with shape (256,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer3.3.bn2.running_var with shape (256,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer3.3.conv3.weight with shape (1024, 256, 1, 1).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer3.3.bn3.weight with shape (1024,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer3.3.bn3.bias with shape (1024,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer3.3.bn3.running_mean with shape (1024,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer3.3.bn3.running_var with shape (1024,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer3.4.conv1.weight with shape (256, 1024, 1, 1).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer3.4.bn1.weight with shape (256,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer3.4.bn1.bias with shape (256,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer3.4.bn1.running_mean with shape (256,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer3.4.bn1.running_var with shape (256,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer3.4.conv2.weight with shape (256, 256, 3, 3).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer3.4.bn2.weight with shape (256,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer3.4.bn2.bias with shape (256,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer3.4.bn2.running_mean with shape (256,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer3.4.bn2.running_var with shape (256,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer3.4.conv3.weight with shape (1024, 256, 1, 1).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer3.4.bn3.weight with shape (1024,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer3.4.bn3.bias with shape (1024,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer3.4.bn3.running_mean with shape (1024,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer3.4.bn3.running_var with shape (1024,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer3.5.conv1.weight with shape (256, 1024, 1, 1).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer3.5.bn1.weight with shape (256,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer3.5.bn1.bias with shape (256,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer3.5.bn1.running_mean with shape (256,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer3.5.bn1.running_var with shape (256,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer3.5.conv2.weight with shape (256, 256, 3, 3).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer3.5.bn2.weight with shape (256,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer3.5.bn2.bias with shape (256,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer3.5.bn2.running_mean with shape (256,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer3.5.bn2.running_var with shape (256,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer3.5.conv3.weight with shape (1024, 256, 1, 1).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer3.5.bn3.weight with shape (1024,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer3.5.bn3.bias with shape (1024,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer3.5.bn3.running_mean with shape (1024,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer3.5.bn3.running_var with shape (1024,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer4.0.conv1.weight with shape (512, 1024, 1, 1).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer4.0.bn1.weight with shape (512,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer4.0.bn1.bias with shape (512,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer4.0.bn1.running_mean with shape (512,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer4.0.bn1.running_var with shape (512,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer4.0.conv2.weight with shape (512, 512, 3, 3).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer4.0.bn2.weight with shape (512,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer4.0.bn2.bias with shape (512,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer4.0.bn2.running_mean with shape (512,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer4.0.bn2.running_var with shape (512,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer4.0.conv3.weight with shape (2048, 512, 1, 1).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer4.0.bn3.weight with shape (2048,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer4.0.bn3.bias with shape (2048,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer4.0.bn3.running_mean with shape (2048,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer4.0.bn3.running_var with shape (2048,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer4.0.downsample.0.weight with shape (2048, 1024, 1, 1).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer4.0.downsample.1.weight with shape (2048,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer4.0.downsample.1.running_mean with shape (2048,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer4.0.downsample.1.running_var with shape (2048,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer4.1.conv1.weight with shape (512, 2048, 1, 1).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer4.1.bn1.weight with shape (512,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer4.1.bn1.bias with shape (512,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer4.1.bn1.running_mean with shape (512,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer4.1.bn1.running_var with shape (512,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer4.1.conv2.weight with shape (512, 512, 3, 3).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer4.1.bn2.weight with shape (512,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer4.1.bn2.bias with shape (512,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer4.1.bn2.running_mean with shape (512,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer4.1.bn2.running_var with shape (512,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer4.1.conv3.weight with shape (2048, 512, 1, 1).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer4.1.bn3.weight with shape (2048,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer4.1.bn3.bias with shape (2048,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer4.1.bn3.running_mean with shape (2048,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer4.1.bn3.running_var with shape (2048,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer4.2.conv1.weight with shape (512, 2048, 1, 1).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer4.2.bn1.weight with shape (512,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer4.2.bn1.bias with shape (512,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer4.2.bn1.running_mean with shape (512,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer4.2.bn1.running_var with shape (512,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer4.2.conv2.weight with shape (512, 512, 3, 3).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer4.2.bn2.weight with shape (512,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer4.2.bn2.bias with shape (512,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer4.2.bn2.running_mean with shape (512,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer4.2.bn2.running_var with shape (512,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer4.2.conv3.weight with shape (2048, 512, 1, 1).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer4.2.bn3.weight with shape (2048,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer4.2.bn3.bias with shape (2048,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer4.2.bn3.running_mean with shape (2048,).\n",
      "DEBUG:onnx2keras:Found weight backbone.body.layer4.2.bn3.running_var with shape (2048,).\n",
      "DEBUG:onnx2keras:Found weight backbone.fpn.inner_blocks.0.0.weight with shape (256, 256, 1, 1).\n",
      "DEBUG:onnx2keras:Found weight backbone.fpn.inner_blocks.0.0.bias with shape (256,).\n",
      "DEBUG:onnx2keras:Found weight backbone.fpn.inner_blocks.1.0.weight with shape (256, 512, 1, 1).\n",
      "DEBUG:onnx2keras:Found weight backbone.fpn.inner_blocks.1.0.bias with shape (256,).\n",
      "DEBUG:onnx2keras:Found weight backbone.fpn.inner_blocks.2.0.weight with shape (256, 1024, 1, 1).\n",
      "DEBUG:onnx2keras:Found weight backbone.fpn.inner_blocks.2.0.bias with shape (256,).\n",
      "DEBUG:onnx2keras:Found weight backbone.fpn.inner_blocks.3.0.weight with shape (256, 2048, 1, 1).\n",
      "DEBUG:onnx2keras:Found weight backbone.fpn.inner_blocks.3.0.bias with shape (256,).\n",
      "DEBUG:onnx2keras:Found weight backbone.fpn.layer_blocks.0.0.weight with shape (256, 256, 3, 3).\n",
      "DEBUG:onnx2keras:Found weight backbone.fpn.layer_blocks.0.0.bias with shape (256,).\n",
      "DEBUG:onnx2keras:Found weight backbone.fpn.layer_blocks.1.0.weight with shape (256, 256, 3, 3).\n",
      "DEBUG:onnx2keras:Found weight backbone.fpn.layer_blocks.1.0.bias with shape (256,).\n",
      "DEBUG:onnx2keras:Found weight backbone.fpn.layer_blocks.2.0.weight with shape (256, 256, 3, 3).\n",
      "DEBUG:onnx2keras:Found weight backbone.fpn.layer_blocks.2.0.bias with shape (256,).\n",
      "DEBUG:onnx2keras:Found weight backbone.fpn.layer_blocks.3.0.weight with shape (256, 256, 3, 3).\n",
      "DEBUG:onnx2keras:Found weight backbone.fpn.layer_blocks.3.0.bias with shape (256,).\n",
      "DEBUG:onnx2keras:Found weight rpn.head.conv.0.0.weight with shape (256, 256, 3, 3).\n",
      "DEBUG:onnx2keras:Found weight rpn.head.conv.0.0.bias with shape (256,).\n",
      "DEBUG:onnx2keras:Found weight rpn.head.cls_logits.weight with shape (7, 256, 1, 1).\n",
      "DEBUG:onnx2keras:Found weight rpn.head.cls_logits.bias with shape (7,).\n",
      "DEBUG:onnx2keras:Found weight rpn.head.bbox_pred.weight with shape (28, 256, 1, 1).\n",
      "DEBUG:onnx2keras:Found weight rpn.head.bbox_pred.bias with shape (28,).\n",
      "DEBUG:onnx2keras:Found weight roi_heads.box_head.fc6.weight with shape (1024, 12544).\n",
      "DEBUG:onnx2keras:Found weight roi_heads.box_head.fc6.bias with shape (1024,).\n",
      "DEBUG:onnx2keras:Found weight roi_heads.box_head.fc7.weight with shape (1024, 1024).\n",
      "DEBUG:onnx2keras:Found weight roi_heads.box_head.fc7.bias with shape (1024,).\n",
      "DEBUG:onnx2keras:Found weight roi_heads.box_predictor.cls_score.weight with shape (2, 1024).\n",
      "DEBUG:onnx2keras:Found weight roi_heads.box_predictor.cls_score.bias with shape (2,).\n",
      "DEBUG:onnx2keras:Found weight roi_heads.box_predictor.bbox_pred.weight with shape (8, 1024).\n",
      "DEBUG:onnx2keras:Found weight roi_heads.box_predictor.bbox_pred.bias with shape (8,).\n",
      "DEBUG:onnx2keras:Found weight roi_heads.keypoint_head.0.weight with shape (512, 256, 3, 3).\n",
      "DEBUG:onnx2keras:Found weight roi_heads.keypoint_head.0.bias with shape (512,).\n",
      "DEBUG:onnx2keras:Found weight roi_heads.keypoint_head.2.weight with shape (512, 512, 3, 3).\n",
      "DEBUG:onnx2keras:Found weight roi_heads.keypoint_head.2.bias with shape (512,).\n",
      "DEBUG:onnx2keras:Found weight roi_heads.keypoint_head.4.weight with shape (512, 512, 3, 3).\n",
      "DEBUG:onnx2keras:Found weight roi_heads.keypoint_head.4.bias with shape (512,).\n",
      "DEBUG:onnx2keras:Found weight roi_heads.keypoint_head.6.weight with shape (512, 512, 3, 3).\n",
      "DEBUG:onnx2keras:Found weight roi_heads.keypoint_head.6.bias with shape (512,).\n",
      "DEBUG:onnx2keras:Found weight roi_heads.keypoint_head.8.weight with shape (512, 512, 3, 3).\n",
      "DEBUG:onnx2keras:Found weight roi_heads.keypoint_head.8.bias with shape (512,).\n",
      "DEBUG:onnx2keras:Found weight roi_heads.keypoint_head.10.weight with shape (512, 512, 3, 3).\n",
      "DEBUG:onnx2keras:Found weight roi_heads.keypoint_head.10.bias with shape (512,).\n",
      "DEBUG:onnx2keras:Found weight roi_heads.keypoint_head.12.weight with shape (512, 512, 3, 3).\n",
      "DEBUG:onnx2keras:Found weight roi_heads.keypoint_head.12.bias with shape (512,).\n",
      "DEBUG:onnx2keras:Found weight roi_heads.keypoint_head.14.weight with shape (512, 512, 3, 3).\n",
      "DEBUG:onnx2keras:Found weight roi_heads.keypoint_head.14.bias with shape (512,).\n",
      "DEBUG:onnx2keras:Found weight roi_heads.keypoint_predictor.kps_score_lowres.weight with shape (512, 4, 4, 4).\n",
      "DEBUG:onnx2keras:Found weight roi_heads.keypoint_predictor.kps_score_lowres.bias with shape (4,).\n",
      "DEBUG:onnx2keras:Found input input_0 with shape (3, 512, 512)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Identity\n",
      "DEBUG:onnx2keras:node_name: backbone.body.layer4.0.downsample.1.bias\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name backbone.body.layer4.0.bn3.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> [-0.05917558 -0.09200171 -0.07034872 ... -0.06190551 -0.06418138\n",
      " -0.06632572]\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Identity\n",
      "DEBUG:onnx2keras:node_name: backbone.body.layer3.0.downsample.1.bias\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name backbone.body.layer3.0.bn3.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> [-0.01436169 -0.02533318 -0.02667828 ...  0.01251766  0.00448023\n",
      " -0.00885909]\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Identity\n",
      "DEBUG:onnx2keras:node_name: backbone.body.layer2.0.downsample.1.bias\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name backbone.body.layer2.0.bn3.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> [ 5.04079051e-02 -5.38011938e-02 -4.97136731e-03  2.05389000e-02\n",
      "  4.73442599e-02 -7.91888306e-06  9.59150866e-03  8.57627168e-02\n",
      "  3.14744785e-02  7.35885501e-02  3.13975313e-03 -3.08145434e-02\n",
      "  4.42122621e-03  9.04321000e-02 -1.70234598e-05 -2.12647524e-02\n",
      " -3.06640416e-02  3.15459892e-02  4.30621654e-02 -7.65981094e-04\n",
      "  4.06090803e-02  7.00544119e-02 -3.26883909e-03 -8.62187733e-07\n",
      "  2.96858139e-02  6.52126521e-02  3.78498458e-03 -3.11907716e-02\n",
      " -3.19021929e-05  4.17266823e-02 -9.74154025e-02  7.27820992e-02\n",
      "  3.03312875e-02 -1.14698913e-02  8.06637295e-03 -2.30923966e-02\n",
      "  9.38584805e-02  4.75611500e-02 -4.69166320e-03  7.52469674e-02\n",
      " -2.99206413e-02  1.58968996e-02 -2.77210381e-02  4.76547629e-02\n",
      "  7.59953354e-03 -5.53374477e-02  7.00809881e-02 -3.38436551e-02\n",
      "  6.63723573e-02 -5.61380275e-02  9.50781554e-02 -8.36076622e-04\n",
      "  5.94201945e-02  4.62292023e-02  9.68705416e-02  1.05701387e-02\n",
      " -1.07523743e-02 -3.75564978e-03  1.13136172e-02 -4.07129573e-06\n",
      "  4.42674272e-02 -3.91433295e-03 -7.98981730e-03  3.31928395e-03\n",
      " -1.08845355e-02  3.34940548e-03 -9.24551040e-02  3.96527685e-02\n",
      " -7.88876332e-06 -2.45302892e-03  1.36554344e-02  1.84369124e-02\n",
      " -1.17770871e-02 -1.00587280e-02 -4.47140858e-02  5.19065298e-02\n",
      " -2.47899834e-02  1.01416372e-01  1.83563661e-02 -5.68349287e-02\n",
      " -1.94700871e-04  1.79894026e-02 -2.36418471e-02  2.57371198e-02\n",
      " -2.23984802e-03  4.89105359e-02  5.51821142e-02 -1.80450629e-03\n",
      "  8.58849883e-02 -1.01441765e-05 -7.65076311e-06 -4.79959771e-02\n",
      " -5.43456115e-02  3.83874811e-02 -1.58904342e-07 -1.36935096e-02\n",
      "  2.14812811e-02  3.75254489e-02 -3.29001318e-03 -1.46406777e-02\n",
      " -5.87187428e-03 -3.05658672e-02  9.16047469e-02  2.97729466e-02\n",
      "  1.06816463e-01 -8.99583683e-04  3.52087095e-02 -4.22071218e-02\n",
      " -3.24972719e-03 -3.26718763e-02  8.30641761e-02  4.85781394e-02\n",
      " -2.85261081e-06 -1.81172732e-02  1.05430789e-01  7.22421035e-02\n",
      " -7.61848642e-03  2.26160954e-03  3.73458974e-02  4.68802266e-02\n",
      " -7.95696769e-03  3.60646993e-02  7.73476064e-02  3.24751390e-03\n",
      " -3.01217586e-02  1.58398971e-01 -3.35493200e-02  5.90582564e-02\n",
      " -5.48565236e-04 -4.52322103e-02 -2.00578757e-02  1.79150421e-02\n",
      "  1.77425537e-02 -7.13217287e-06  1.10038415e-01 -7.15859421e-03\n",
      " -7.02382007e-04  3.54499067e-03 -1.41939313e-06 -5.07233478e-03\n",
      "  1.07189985e-02 -2.68459208e-02 -1.57242101e-02 -4.80290473e-04\n",
      " -4.12288457e-02  1.04285832e-02  4.78176177e-02 -2.15546917e-02\n",
      "  2.17281319e-02 -2.04726215e-02  2.55822215e-05  3.20866480e-02\n",
      "  6.41790628e-02 -6.26774054e-05  1.17625043e-01  3.70766707e-02\n",
      "  8.79000872e-02 -9.17326724e-06  3.50065865e-02 -1.57799218e-02\n",
      " -1.46454163e-02  1.14926562e-01  3.55528258e-02  3.80601510e-02\n",
      "  5.22140376e-02 -1.38838345e-03 -1.92729570e-02 -3.34582478e-02\n",
      " -3.79743427e-02 -1.77679416e-02 -1.35000687e-06  7.12250825e-03\n",
      "  9.30385813e-02  1.48884788e-01 -2.72378038e-05 -5.64810224e-02\n",
      "  1.06396198e-01 -3.81113663e-02  5.76255098e-02 -1.18713584e-02\n",
      " -3.74515727e-02 -8.35337210e-03  1.31147662e-02  5.22400960e-02\n",
      "  1.46090034e-02  1.36911899e-01 -2.82387327e-06  5.48314024e-03\n",
      "  7.07063749e-02 -3.66909727e-02 -1.77477789e-03 -1.10443020e-02\n",
      "  2.90122349e-02  1.14992678e-01  1.54051766e-01  7.92849436e-03\n",
      " -1.17320816e-07 -2.64128279e-02  1.22135216e-02  8.36624112e-03\n",
      " -6.29022588e-06  5.00124209e-02 -6.51544705e-03  5.02667502e-02\n",
      " -7.11984342e-07 -4.50925119e-02  2.56030206e-02  3.97566333e-02\n",
      "  4.92777266e-02 -9.73678939e-03 -1.03086908e-03  8.03537443e-02\n",
      "  4.95029464e-02 -1.01346077e-05 -2.04693396e-02 -2.30645519e-02\n",
      " -1.09670293e-02  1.39915809e-01  1.36522343e-02  2.27914900e-02\n",
      "  5.50287440e-02 -1.33923516e-02 -1.29684821e-07 -3.25538889e-02\n",
      "  2.64249779e-02  2.01183390e-02  5.85256629e-02  1.98206052e-01\n",
      "  2.15305295e-03  1.38332602e-02 -1.21650370e-02  7.62264058e-02\n",
      "  1.00873776e-01 -2.91284285e-02 -1.11653101e-07  3.41907851e-02\n",
      " -2.73889309e-05 -6.73057372e-03  5.20809703e-02  5.82332117e-03\n",
      " -1.84362274e-04  1.90587804e-01  2.47955080e-02  8.90794098e-02\n",
      " -2.87397322e-03 -5.12456112e-02  2.34416798e-02  1.34850008e-04\n",
      " -4.45325784e-02  3.77716944e-02  4.52650711e-02  1.29819512e-01\n",
      " -7.08625745e-03  2.94662779e-03  2.12293714e-02  6.86783046e-02\n",
      " -2.41075195e-02 -5.96730411e-03  3.35829817e-02  5.18136751e-03\n",
      " -3.40578929e-02  2.45278683e-02  3.29796853e-03  8.53375122e-02\n",
      "  4.66584414e-03  1.14949442e-01  2.12754030e-02  2.02977043e-02\n",
      "  6.53522834e-02  4.85044830e-02 -1.22370475e-04 -2.22012345e-02\n",
      " -3.26897839e-06  5.65474294e-02  9.21434071e-03  5.31766824e-02\n",
      "  1.31208552e-02  5.87784946e-02 -1.06276227e-02 -4.66469973e-02\n",
      " -3.81201715e-03  1.62805002e-02 -1.62935182e-02  4.69924957e-02\n",
      "  8.24342519e-02 -3.76414210e-02  9.05867945e-03 -2.10603909e-03\n",
      " -2.25056726e-02 -4.00341116e-02 -1.71601363e-02 -9.88766202e-04\n",
      " -4.36682068e-02 -4.36539873e-02 -7.97614828e-02  8.09946621e-04\n",
      "  3.33625972e-02 -9.54077987e-05  2.46345475e-02 -1.21864816e-03\n",
      "  8.88572726e-03 -2.52901148e-02  1.54151889e-02  4.17273827e-02\n",
      " -1.44988466e-02 -2.50074989e-03 -4.23520915e-02  2.31498443e-02\n",
      "  1.02517297e-02 -5.08265831e-02 -2.98429690e-02 -1.79752769e-05\n",
      " -2.42557661e-07 -2.32000070e-06  8.79604518e-02 -1.95941050e-02\n",
      " -1.42852571e-02  1.37671307e-01 -5.40947156e-07  7.27191865e-02\n",
      "  1.54252835e-02  2.25841813e-03  1.67019144e-02 -1.87193963e-03\n",
      "  4.09831740e-02 -1.51145798e-07 -6.98958859e-02 -1.15849813e-02\n",
      " -3.82199301e-03  3.92089635e-02  7.93920979e-02 -3.12745245e-03\n",
      " -6.07930190e-07 -6.50541410e-02 -4.61217901e-03  2.28809249e-02\n",
      " -1.52980303e-02  7.13321939e-02 -2.55698375e-02 -2.57295482e-02\n",
      "  1.01773776e-01 -3.83458030e-03  1.17470406e-01 -3.23413499e-02\n",
      "  1.20231144e-01  9.68486257e-03 -1.89667261e-07  9.64797288e-02\n",
      " -3.46350018e-03  1.38675377e-01 -7.06950144e-04 -9.47826579e-02\n",
      " -4.27725632e-03  3.69391851e-02  1.43409595e-01  8.61905143e-03\n",
      "  3.49053107e-02  1.31420463e-01  2.16861498e-02 -3.21553983e-02\n",
      "  2.22503040e-02  3.36697139e-02  1.18405407e-03 -4.63074632e-02\n",
      " -6.75433766e-05 -1.92898326e-02 -1.02939270e-03 -2.23244354e-02\n",
      "  6.64701536e-02 -2.04654802e-02 -5.00824945e-06  1.16990127e-01\n",
      "  3.54962312e-02  2.23710947e-02  7.60980099e-02 -3.12739387e-02\n",
      " -2.63781231e-02  4.44310717e-03 -1.32758720e-02  5.58198169e-02\n",
      " -2.93406751e-02 -3.42406973e-04  1.29482940e-01  4.85263020e-02\n",
      "  1.21484499e-03  1.55320605e-02 -5.98268925e-05  9.06627774e-02\n",
      "  6.65597171e-02 -2.18572356e-02 -4.25241014e-04  8.43966089e-04\n",
      "  7.51893669e-02 -4.03823666e-02 -5.73503179e-03  1.30590230e-01\n",
      "  8.92094299e-02 -5.23900352e-02  8.33465066e-03  3.69058289e-02\n",
      " -1.91984077e-06 -2.57537737e-02 -1.80602204e-02  1.57066677e-02\n",
      " -7.24624321e-02 -5.39316982e-02  3.36041898e-02  5.37533779e-03\n",
      "  9.24540311e-03 -9.63428761e-07  1.10550132e-02  9.31399595e-03\n",
      "  1.23751782e-01 -2.40522809e-07  4.79034102e-03 -2.49637160e-02\n",
      "  7.81058474e-03 -2.53638998e-02 -1.75564699e-02  1.11335348e-02\n",
      " -1.58448573e-02 -4.87870798e-02  1.73036929e-03 -1.96806863e-02\n",
      " -1.20927335e-03 -1.86201949e-02 -1.92530365e-06  6.88441982e-03\n",
      " -1.25307804e-02 -2.64125614e-04 -8.76459217e-06  4.80100811e-02\n",
      "  8.75246227e-02 -8.02431623e-06 -1.71143845e-01 -1.34331444e-02\n",
      " -4.00588214e-02 -5.17957695e-02  6.72733597e-03  7.62713328e-03\n",
      "  1.74118150e-02  7.14508370e-02 -6.35348037e-02  1.43902913e-01\n",
      "  5.22248447e-02 -2.68568341e-02 -2.35250945e-06  9.41379461e-03\n",
      " -2.44417018e-03 -1.68365339e-04 -2.28592884e-02 -2.33801825e-06\n",
      " -4.70661462e-07  2.90318634e-02 -4.43174271e-03  1.28231542e-02\n",
      "  6.29715472e-02 -2.86935959e-02  1.04358979e-01  1.20984562e-01\n",
      " -6.83841342e-03  6.18027374e-02 -2.16824338e-02  3.35202515e-02\n",
      "  1.84416503e-01  2.04519518e-02 -2.25287676e-02 -3.80238134e-07\n",
      "  4.75025699e-02 -1.68490205e-02 -3.56224068e-02  1.30896300e-01\n",
      " -1.04217364e-07  6.65212870e-02  8.81227702e-02  1.29627846e-02\n",
      "  6.94950521e-02  2.28975923e-03 -8.15410912e-03 -5.98399565e-02\n",
      " -3.73829366e-03  1.66822970e-02  1.87095050e-02 -3.39636244e-02\n",
      " -6.98187063e-03 -8.87849648e-03 -1.65503752e-05  3.66954952e-02\n",
      "  7.47696906e-02 -3.64427688e-03 -2.77023837e-02 -5.79236597e-02\n",
      "  5.38311601e-02  3.85189876e-02  9.70224068e-02 -4.27793115e-02\n",
      " -1.28270611e-02 -5.47933765e-02 -6.00012555e-08  7.13817170e-03\n",
      "  6.78380951e-02 -9.02074426e-02 -2.30345558e-02 -8.59346997e-04\n",
      "  2.05211323e-02  7.87423402e-02  3.60455923e-02 -7.29880808e-03\n",
      " -4.18326557e-02 -8.71376301e-07  7.53001198e-02  1.63501069e-01]\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Identity\n",
      "DEBUG:onnx2keras:node_name: backbone.body.layer1.0.downsample.1.bias\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name backbone.body.layer1.0.bn3.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> [-4.75214468e-03  7.33815804e-02  2.98811793e-02  5.42495027e-02\n",
      " -4.21023592e-02  4.57482487e-02  7.04443753e-02  1.36120200e-01\n",
      "  9.59702283e-02  8.68024230e-02  4.65879515e-02  8.78787786e-03\n",
      " -5.56304539e-03  3.55923586e-02  6.02449588e-02  2.94965412e-02\n",
      "  1.14869557e-01  1.00224346e-01 -7.05652535e-02  5.78527860e-02\n",
      "  5.91339059e-02  3.19855250e-02 -2.06463710e-06 -1.11736774e-07\n",
      "  9.54737365e-02 -1.21428247e-03 -1.06448710e-01 -7.66474335e-03\n",
      "  4.32685874e-02  1.01565244e-02  3.32975201e-02  1.06816851e-02\n",
      "  5.05052581e-02 -2.51734890e-02  5.80023266e-02 -3.95097472e-02\n",
      "  2.43341252e-02  2.46014260e-02  1.91362053e-02  8.74311253e-02\n",
      " -1.08095156e-02  4.61220369e-02 -2.81692017e-03  6.68853596e-02\n",
      "  3.95176299e-02 -4.45092192e-05  4.49380316e-02  1.77480895e-02\n",
      " -1.17505074e-01  3.78232785e-02  1.14944637e-01  1.17070675e-01\n",
      " -3.60707787e-07  3.72260660e-02 -4.09076773e-02  8.15623626e-02\n",
      "  1.44873917e-01  5.98094100e-03  2.41730046e-02 -1.35885617e-02\n",
      " -5.16694151e-02  5.47983423e-02  4.63373438e-02  2.22708620e-02\n",
      " -1.47904160e-07  4.16437984e-02  3.86249763e-03  2.16029901e-02\n",
      " -8.67286883e-03  9.42922980e-02 -4.43692654e-02 -6.02939281e-07\n",
      "  2.16520846e-01  8.95513743e-02  1.87069289e-02  2.06666607e-02\n",
      " -2.95890914e-03 -2.16872260e-01  5.02599254e-02  3.84734981e-02\n",
      "  5.91345280e-02  3.61034535e-02  9.94974747e-02 -2.06774785e-05\n",
      "  1.42527834e-01  1.90720111e-01  3.80417928e-02 -1.26050838e-06\n",
      " -5.35478489e-03 -2.00822751e-06  9.85974744e-02 -9.42226574e-02\n",
      " -4.13428843e-02 -8.26712698e-03 -2.88332552e-02  1.06741577e-01\n",
      "  1.55569598e-01  2.79034991e-02  5.31386063e-02 -3.12061831e-02\n",
      "  3.94832380e-02 -7.75365208e-07  3.00366199e-03  3.55182886e-02\n",
      "  7.98599795e-02  2.37929150e-02 -1.29811600e-01 -1.35110588e-06\n",
      " -6.72462508e-02  1.73376828e-01  9.57825929e-02  9.18387994e-02\n",
      " -4.32015993e-02  7.84019902e-02 -6.34754397e-05  5.40355220e-02\n",
      "  4.69692536e-02 -2.44102267e-07  1.57090187e-01  2.92723421e-02\n",
      "  3.07575539e-02 -1.50722519e-01  9.30472538e-02 -7.62400596e-05\n",
      "  1.11698106e-01  1.55334082e-02  6.09135926e-02 -5.98699669e-04\n",
      "  2.63660047e-02  5.26009426e-02  1.66005790e-01 -3.97851020e-02\n",
      "  5.76325729e-02 -2.70450118e-06 -3.37083679e-06  1.15460023e-01\n",
      "  4.91881594e-02 -1.48827601e-02  4.44275364e-02 -3.11498865e-02\n",
      " -2.36529335e-02  6.57786876e-02  6.70559853e-02  9.83897597e-02\n",
      " -2.37848327e-01  3.30354497e-02  1.90172270e-01  1.63238794e-02\n",
      " -3.07380617e-01  3.11869513e-02 -2.16415897e-01  1.18533131e-02\n",
      " -4.24249843e-03  5.62958559e-03 -7.53154531e-02  1.31892664e-02\n",
      "  2.17981990e-02  6.32514129e-04  4.87076957e-03 -5.79057597e-02\n",
      "  5.18941954e-02  1.33438557e-01 -1.59520432e-02  1.65320992e-01\n",
      " -2.83051841e-02  4.05122060e-03  2.76005547e-02  1.28132440e-02\n",
      " -1.54984486e-03  2.95021255e-02  8.63147527e-02 -4.08211388e-02\n",
      " -3.26294862e-02 -1.53963175e-02 -1.88293889e-05  1.05589610e-02\n",
      "  3.54162976e-02  1.24150872e-01  7.76866823e-02 -1.11047160e-02\n",
      "  1.89612024e-02 -5.84417991e-02 -1.72474012e-02 -4.91538122e-02\n",
      "  1.15532633e-02 -2.08097754e-06  1.38717983e-02  1.08458281e-01\n",
      "  6.85311928e-02  1.76715598e-01  3.56343873e-02 -4.02938388e-02\n",
      "  4.61630337e-02  3.34979892e-02  2.22825129e-02  4.66886349e-02\n",
      "  2.92492975e-02  1.03799291e-01  2.79869381e-02 -4.73133296e-05\n",
      "  8.36066976e-02  7.96284303e-02 -2.05398078e-06  1.27646297e-01\n",
      " -2.43368930e-07  1.12808205e-01 -1.03579490e-02 -4.99320496e-03\n",
      "  9.12792981e-02  5.01663089e-02 -1.94972642e-02 -3.38878366e-04\n",
      " -3.01614609e-02  7.71164522e-02 -2.97155930e-06  7.07047060e-02\n",
      "  2.36469023e-02  3.57550755e-02 -6.36783168e-02  1.04907013e-01\n",
      "  1.13825954e-01  1.30689237e-03 -4.91352007e-02  1.15383714e-01\n",
      " -6.02265522e-02  9.93916881e-04  6.47805631e-02  7.63787478e-02\n",
      "  5.98528311e-02  1.19611897e-01 -5.16705401e-02  5.28030135e-02\n",
      "  2.71437578e-02  5.19993119e-02  1.90736353e-01  1.71429478e-02\n",
      "  5.51775210e-02  1.25718504e-01 -2.67540128e-03 -3.12759839e-02\n",
      "  4.70694117e-02  5.16900793e-02 -5.94750652e-03  2.96333786e-02\n",
      "  1.91219583e-01  1.40008647e-02 -4.08851571e-04  2.39238366e-02\n",
      " -3.66115905e-02  3.51779796e-02  8.26148242e-02  6.92142099e-02\n",
      "  1.17809080e-01  3.43319438e-02  1.94727987e-01  3.27479057e-02]\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Constant\n",
      "DEBUG:onnx2keras:node_name: /Constant_output_0\n",
      "DEBUG:onnx2keras:node_params: {'value': array(1, dtype=int64), 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> 1\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Constant\n",
      "DEBUG:onnx2keras:node_name: /Constant_1_output_0\n",
      "DEBUG:onnx2keras:node_params: {'value': array(2, dtype=int64), 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> 2\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Constant\n",
      "DEBUG:onnx2keras:node_name: /transform/Constant_output_0\n",
      "DEBUG:onnx2keras:node_params: {'value': array([[[0.485]],\n",
      "\n",
      "       [[0.456]],\n",
      "\n",
      "       [[0.406]]], dtype=float32), 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> [[[0.485]]\n",
      "\n",
      " [[0.456]]\n",
      "\n",
      " [[0.406]]]\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Sub\n",
      "DEBUG:onnx2keras:node_name: /transform/Sub_output_0\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name input_0).\n",
      "DEBUG:onnx2keras:Check input 1 (name /transform/Constant_output_0).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:sub:Convert inputs to Keras/TF layers if needed.\n",
      "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(3, 3, 512, 512), dtype=tf.float32, name=None), name='transform/Sub_output_0/sub:0', description=\"created by layer 'transform/Sub_output_0'\")\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Constant\n",
      "DEBUG:onnx2keras:node_name: /transform/Constant_1_output_0\n",
      "DEBUG:onnx2keras:node_params: {'value': array([[[0.229]],\n",
      "\n",
      "       [[0.224]],\n",
      "\n",
      "       [[0.225]]], dtype=float32), 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> [[[0.229]]\n",
      "\n",
      " [[0.224]]\n",
      "\n",
      " [[0.225]]]\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Div\n",
      "DEBUG:onnx2keras:node_name: /transform/Div_output_0\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name /transform/Sub_output_0).\n",
      "DEBUG:onnx2keras:Check input 1 (name /transform/Constant_1_output_0).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:div:Convert inputs to Keras/TF layers if needed.\n",
      "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(3, 3, 512, 512), dtype=tf.float32, name=None), name='transform/Div_output_0/truediv:0', description=\"created by layer 'transform/Div_output_0'\")\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Constant\n",
      "DEBUG:onnx2keras:node_name: /transform/Constant_2_output_0\n",
      "DEBUG:onnx2keras:node_params: {'value': array(0, dtype=int64), 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> 0\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Constant\n",
      "DEBUG:onnx2keras:node_name: /transform/Constant_3_output_0\n",
      "DEBUG:onnx2keras:node_params: {'value': array([512, 512], dtype=int64), 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> [512 512]\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: ReduceMin\n",
      "DEBUG:onnx2keras:node_name: /transform/ReduceMin_output_0\n",
      "DEBUG:onnx2keras:node_params: {'keepdims': 0, 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name /transform/Constant_3_output_0).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> tf.Tensor(512, shape=(), dtype=int32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Cast\n",
      "DEBUG:onnx2keras:node_name: /transform/Cast_output_0\n",
      "DEBUG:onnx2keras:node_params: {'to': 1, 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name /transform/ReduceMin_output_0).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> tf.Tensor(512.0, shape=(), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: ReduceMax\n",
      "DEBUG:onnx2keras:node_name: /transform/ReduceMax_output_0\n",
      "DEBUG:onnx2keras:node_params: {'keepdims': 0, 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name /transform/Constant_3_output_0).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> tf.Tensor(512, shape=(), dtype=int32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Cast\n",
      "DEBUG:onnx2keras:node_name: /transform/Cast_1_output_0\n",
      "DEBUG:onnx2keras:node_params: {'to': 1, 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name /transform/ReduceMax_output_0).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> tf.Tensor(512.0, shape=(), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Reciprocal\n",
      "DEBUG:onnx2keras:node_name: /transform/Reciprocal_output_0\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name /transform/Cast_output_0).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> tf.Tensor(0.001953125, shape=(), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Constant\n",
      "DEBUG:onnx2keras:node_name: /transform/Constant_4_output_0\n",
      "DEBUG:onnx2keras:node_params: {'value': array(800., dtype=float32), 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> 800.0\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Mul\n",
      "DEBUG:onnx2keras:node_name: /transform/Mul_output_0\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name /transform/Reciprocal_output_0).\n",
      "DEBUG:onnx2keras:Check input 1 (name /transform/Constant_4_output_0).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:mul:Convert inputs to Keras/TF layers if needed.\n",
      "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(), dtype=tf.float32, name=None), name='transform/Mul_output_0/mul:0', description=\"created by layer 'transform/Mul_output_0'\")\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Reciprocal\n",
      "DEBUG:onnx2keras:node_name: /transform/Reciprocal_1_output_0\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name /transform/Cast_1_output_0).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> tf.Tensor(0.001953125, shape=(), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Constant\n",
      "DEBUG:onnx2keras:node_name: /transform/Constant_5_output_0\n",
      "DEBUG:onnx2keras:node_params: {'value': array(1333., dtype=float32), 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> 1333.0\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Mul\n",
      "DEBUG:onnx2keras:node_name: /transform/Mul_1_output_0\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name /transform/Reciprocal_1_output_0).\n",
      "DEBUG:onnx2keras:Check input 1 (name /transform/Constant_5_output_0).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:mul:Convert inputs to Keras/TF layers if needed.\n",
      "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(), dtype=tf.float32, name=None), name='transform/Mul_1_output_0/mul:0', description=\"created by layer 'transform/Mul_1_output_0'\")\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Min\n",
      "DEBUG:onnx2keras:node_name: /transform/Min_output_0\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name /transform/Mul_output_0).\n",
      "DEBUG:onnx2keras:Check input 1 (name /transform/Mul_1_output_0).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(), dtype=tf.float32, name=None), name='transform/Min_output_0/Minimum:0', description=\"created by layer 'transform/Min_output_0'\")\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Constant\n",
      "DEBUG:onnx2keras:node_name: /transform/Constant_6_output_0\n",
      "DEBUG:onnx2keras:node_params: {'value': array([0], dtype=int64), 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> [0]\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Unsqueeze\n",
      "DEBUG:onnx2keras:node_name: /transform/Unsqueeze_output_0\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name /transform/Div_output_0).\n",
      "DEBUG:onnx2keras:Check input 1 (name /transform/Constant_6_output_0).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(3, 3, 512, 512, 1), dtype=tf.float32, name=None), name='transform/Unsqueeze_output_0/ExpandDims:0', description=\"created by layer 'transform/Unsqueeze_output_0'\")\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Constant\n",
      "DEBUG:onnx2keras:node_name: /transform/Constant_7_output_0\n",
      "DEBUG:onnx2keras:node_params: {'value': array(True), 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> True\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Cast\n",
      "DEBUG:onnx2keras:node_name: /transform/Cast_2_output_0\n",
      "DEBUG:onnx2keras:node_params: {'to': 1, 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name /transform/Min_output_0).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(), dtype=tf.float32, name=None), name='Placeholder:0', description=\"created by layer 'transform/Cast_2_output_0'\")\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Constant\n",
      "DEBUG:onnx2keras:node_name: /transform/Constant_8_output_0\n",
      "DEBUG:onnx2keras:node_params: {'value': array(512., dtype=float32), 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> 512.0\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Mul\n",
      "DEBUG:onnx2keras:node_name: /transform/Mul_2_output_0\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name /transform/Constant_8_output_0).\n",
      "DEBUG:onnx2keras:Check input 1 (name /transform/Cast_2_output_0).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:mul:Convert inputs to Keras/TF layers if needed.\n",
      "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(), dtype=tf.float32, name=None), name='transform/Mul_2_output_0/mul:0', description=\"created by layer 'transform/Mul_2_output_0'\")\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Cast\n",
      "DEBUG:onnx2keras:node_name: /transform/Cast_3_output_0\n",
      "DEBUG:onnx2keras:node_params: {'to': 1, 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name /transform/Mul_2_output_0).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(), dtype=tf.float32, name=None), name='Placeholder:0', description=\"created by layer 'transform/Cast_3_output_0'\")\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Floor\n",
      "DEBUG:onnx2keras:node_name: /transform/Floor_output_0\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name /transform/Cast_3_output_0).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(), dtype=tf.float32, name=None), name='transform/Floor_output_0/Floor:0', description=\"created by layer 'transform/Floor_output_0'\")\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Constant\n",
      "DEBUG:onnx2keras:node_name: /transform/Constant_9_output_0\n",
      "DEBUG:onnx2keras:node_params: {'value': array(3, dtype=int64), 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> 3\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Constant\n",
      "DEBUG:onnx2keras:node_name: /transform/Constant_10_output_0\n",
      "DEBUG:onnx2keras:node_params: {'value': array(512., dtype=float32), 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> 512.0\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Mul\n",
      "DEBUG:onnx2keras:node_name: /transform/Mul_3_output_0\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name /transform/Constant_10_output_0).\n",
      "DEBUG:onnx2keras:Check input 1 (name /transform/Cast_2_output_0).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:mul:Convert inputs to Keras/TF layers if needed.\n",
      "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(), dtype=tf.float32, name=None), name='transform/Mul_3_output_0/mul:0', description=\"created by layer 'transform/Mul_3_output_0'\")\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Cast\n",
      "DEBUG:onnx2keras:node_name: /transform/Cast_4_output_0\n",
      "DEBUG:onnx2keras:node_params: {'to': 1, 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name /transform/Mul_3_output_0).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(), dtype=tf.float32, name=None), name='Placeholder:0', description=\"created by layer 'transform/Cast_4_output_0'\")\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Floor\n",
      "DEBUG:onnx2keras:node_name: /transform/Floor_1_output_0\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name /transform/Cast_4_output_0).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(), dtype=tf.float32, name=None), name='transform/Floor_1_output_0/Floor:0', description=\"created by layer 'transform/Floor_1_output_0'\")\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Constant\n",
      "DEBUG:onnx2keras:node_name: onnx::Unsqueeze_348\n",
      "DEBUG:onnx2keras:node_params: {'value': array([0], dtype=int64), 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> [0]\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Unsqueeze\n",
      "DEBUG:onnx2keras:node_name: /transform/Unsqueeze_1_output_0\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name /transform/Floor_output_0).\n",
      "DEBUG:onnx2keras:Check input 1 (name onnx::Unsqueeze_348).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(1,), dtype=tf.float32, name=None), name='transform/Unsqueeze_1_output_0/ExpandDims:0', description=\"created by layer 'transform/Unsqueeze_1_output_0'\")\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Constant\n",
      "DEBUG:onnx2keras:node_name: onnx::Unsqueeze_350\n",
      "DEBUG:onnx2keras:node_params: {'value': array([0], dtype=int64), 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:... found all, continue\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of inputs is not equal 1 for unsqueeze layer\n",
      "Number of inputs is not equal 1 for unsqueeze layer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:onnx2keras:Output TF Layer -> [0]\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Unsqueeze\n",
      "DEBUG:onnx2keras:node_name: /transform/Unsqueeze_2_output_0\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name /transform/Floor_1_output_0).\n",
      "DEBUG:onnx2keras:Check input 1 (name onnx::Unsqueeze_350).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(1,), dtype=tf.float32, name=None), name='transform/Unsqueeze_2_output_0/ExpandDims:0', description=\"created by layer 'transform/Unsqueeze_2_output_0'\")\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Concat\n",
      "DEBUG:onnx2keras:node_name: /transform/Concat_output_0\n",
      "DEBUG:onnx2keras:node_params: {'axis': 0, 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name /transform/Unsqueeze_1_output_0).\n",
      "DEBUG:onnx2keras:Check input 1 (name /transform/Unsqueeze_2_output_0).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:concat:Concat Keras layers.\n",
      "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(2,), dtype=tf.float32, name=None), name='transform/Concat_output_0/concat:0', description=\"created by layer 'transform/Concat_output_0'\")\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Shape\n",
      "DEBUG:onnx2keras:node_name: /transform/Shape_output_0\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name /transform/Unsqueeze_output_0).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:shape:Actual shape:\n",
      "DEBUG:onnx2keras:shape:[  3   3 512 512   1]\n",
      "DEBUG:onnx2keras:Output TF Layer -> [  3   3 512 512   1]\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Constant\n",
      "DEBUG:onnx2keras:node_name: /transform/Constant_11_output_0\n",
      "DEBUG:onnx2keras:node_params: {'value': array([0], dtype=int64), 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> [0]\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Constant\n",
      "DEBUG:onnx2keras:node_name: /transform/Constant_12_output_0\n",
      "DEBUG:onnx2keras:node_params: {'value': array([0], dtype=int64), 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> [0]\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Constant\n",
      "DEBUG:onnx2keras:node_name: /transform/Constant_13_output_0\n",
      "DEBUG:onnx2keras:node_params: {'value': array([2], dtype=int64), 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> [2]\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Slice\n",
      "DEBUG:onnx2keras:node_name: /transform/Slice_output_0\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name /transform/Shape_output_0).\n",
      "DEBUG:onnx2keras:Check input 1 (name /transform/Constant_12_output_0).\n",
      "DEBUG:onnx2keras:Check input 2 (name /transform/Constant_13_output_0).\n",
      "DEBUG:onnx2keras:Check input 3 (name /transform/Constant_11_output_0).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:slice:Slice numpy constants\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Cast\n",
      "DEBUG:onnx2keras:node_name: /transform/Cast_5_output_0\n",
      "DEBUG:onnx2keras:node_params: {'to': 7, 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name /transform/Concat_output_0).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(2,), dtype=tf.int64, name=None), name='transform/Cast_5_output_0/Cast:0', description=\"created by layer 'transform/Cast_5_output_0'\")\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Concat\n",
      "DEBUG:onnx2keras:node_name: /transform/Concat_1_output_0\n",
      "DEBUG:onnx2keras:node_params: {'axis': 0, 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name /transform/Slice_output_0).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Check input 1 (name /transform/Cast_5_output_0).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:concat:Concat Keras layers.\n",
      "DEBUG:onnx2keras:Output TF Layer -> KerasTensor(type_spec=TensorSpec(shape=(2,), dtype=tf.int64, name=None), name='transform/Cast_5_output_0/Cast:0', description=\"created by layer 'transform/Cast_5_output_0'\")\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Resize\n",
      "DEBUG:onnx2keras:node_name: /transform/Resize_output_0\n",
      "DEBUG:onnx2keras:node_params: {'coordinate_transformation_mode': b'half_pixel', 'cubic_coeff_a': -0.75, 'mode': b'linear', 'nearest_mode': b'floor', 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name /transform/Unsqueeze_output_0).\n",
      "DEBUG:onnx2keras:Check input 1 (name ).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Check input 2 (name ).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Check input 3 (name /transform/Concat_1_output_0).\n",
      "DEBUG:onnx2keras:... found all, continue\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of inputs is not equal 1 for unsqueeze layer\n",
      "{'change_ordering': False, 'name_policy': None}\n",
      "Not implemented\n",
      "Not implemented\n",
      "Current node is not in weights / model inputs / layers. Skipping\n",
      "Current node is not in weights / model inputs / layers. Skipping\n",
      "Current node is not in weights / model inputs / layers. Skipping\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Resize'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m model\u001b[39m.\u001b[39mto(\u001b[39m'\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      2\u001b[0m model\u001b[39m.\u001b[39meval()\n\u001b[1;32m----> 4\u001b[0m k_model \u001b[39m=\u001b[39m pytorch_to_keras(model, [x_reshaped], [(\u001b[39m3\u001b[39;49m, \u001b[39m512\u001b[39;49m, \u001b[39m512\u001b[39;49m)], verbose\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, change_ordering\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "File \u001b[1;32mc:\\Users\\Hisku\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch2keras\\converter.py:81\u001b[0m, in \u001b[0;36mpytorch_to_keras\u001b[1;34m(model, args, input_shapes, change_ordering, verbose, name_policy, use_optimizer, do_constant_folding)\u001b[0m\n\u001b[0;32m     78\u001b[0m     logger\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39mRunning optimizer:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(optimizer2run))\n\u001b[0;32m     79\u001b[0m     onnx_model \u001b[39m=\u001b[39m optimizer\u001b[39m.\u001b[39moptimize(onnx_model, optimizer2run)\n\u001b[1;32m---> 81\u001b[0m k_model \u001b[39m=\u001b[39m onnx_to_keras(onnx_model\u001b[39m=\u001b[39;49monnx_model, input_names\u001b[39m=\u001b[39;49minput_names,\n\u001b[0;32m     82\u001b[0m                         input_shapes\u001b[39m=\u001b[39;49minput_shapes, name_policy\u001b[39m=\u001b[39;49mname_policy,\n\u001b[0;32m     83\u001b[0m                         verbose\u001b[39m=\u001b[39;49mverbose, change_ordering\u001b[39m=\u001b[39;49mchange_ordering)\n\u001b[0;32m     85\u001b[0m \u001b[39mreturn\u001b[39;00m k_model\n",
      "File \u001b[1;32mc:\\Users\\Hisku\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\onnx2keras\\converter.py:176\u001b[0m, in \u001b[0;36monnx_to_keras\u001b[1;34m(onnx_model, input_names, input_shapes, name_policy, verbose, change_ordering)\u001b[0m\n\u001b[0;32m    173\u001b[0m     logger\u001b[39m.\u001b[39mdebug(\u001b[39m'\u001b[39m\u001b[39m... found all, continue\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    175\u001b[0m keras\u001b[39m.\u001b[39mbackend\u001b[39m.\u001b[39mset_image_data_format(\u001b[39m'\u001b[39m\u001b[39mchannels_first\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m--> 176\u001b[0m AVAILABLE_CONVERTERS[node_type](\n\u001b[0;32m    177\u001b[0m     node,\n\u001b[0;32m    178\u001b[0m     node_params,\n\u001b[0;32m    179\u001b[0m     layers,\n\u001b[0;32m    180\u001b[0m     lambda_funcs,\n\u001b[0;32m    181\u001b[0m     node_name,\n\u001b[0;32m    182\u001b[0m     keras_names\n\u001b[0;32m    183\u001b[0m )\n\u001b[0;32m    184\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(keras_names, \u001b[39mlist\u001b[39m):\n\u001b[0;32m    185\u001b[0m     keras_names \u001b[39m=\u001b[39m keras_names[\u001b[39m0\u001b[39m]\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Resize'"
     ]
    }
   ],
   "source": [
    "model.to('cpu')\n",
    "model.eval()\n",
    "\n",
    "k_model = pytorch_to_keras(model, [x_reshaped], [(3, 512, 512)], verbose=True, change_ordering=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optionally, if you want to export the model to ONNX:\n",
    "model.to('cpu')\n",
    "torch.onnx.export(model, x_reshaped, \"./assets/keypoint_rcnn.onnx\", opset_version = 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_model = onnx.load('./assets/keypoint_rcnn.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Model: ./assets/keypoint_rcnn.onnx\n",
      "Fixing Resize nodes...\n",
      "Creating new fixed graph...\n",
      "Creating new fixed model...\n",
      "Saving new model as: ./assets/keypoint_rcnn_updated.onnx\n"
     ]
    }
   ],
   "source": [
    "# fix onnx resize nodes\n",
    "from onnx_utils import fix_onnx_resize_nodes\n",
    "\n",
    "fix_onnx_resize_nodes('./assets/keypoint_rcnn.onnx', './assets/keypoint_rcnn_updated.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_model_updated = onnx.load('./assets/keypoint_rcnn_updated.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx.checker.check_model(onnx_model_updated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_rep = prepare(onnx_model, strict=False, gen_tensor_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs: ['image.1', 'image.5']\n",
      "outputs: ['3973', '3295', '3294', '3982', 'end_scores.7', '4003', '3414', '3413', '4012', 'end_scores.21']\n",
      "tensor_dict:\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "# Input nodes to the model\n",
    "print('inputs:', tf_rep.inputs)\n",
    "\n",
    "# Output nodes from the model\n",
    "print('outputs:', tf_rep.outputs)\n",
    "\n",
    "# All nodes in the model\n",
    "print('tensor_dict:')\n",
    "print(tf_rep.tensor_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_rep.export_graph('./assets/keypoint_tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove / from the beginning of model scope names to avoid issues in tensorflow\n",
    "for i in onnx_model.graph.initializer:\n",
    "    i.name = i.name[1:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from onnxruntime.quantization import quantize_dynamic, QuantType\n",
    "\n",
    "quantize_dynamic('./assets/keypoint_rcnn.onnx', './assets/keypoint_rcnn_quant.onnx', weight_type=QuantType.QUInt8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantized_model = onnx.load('./assets/keypoint_rcnn_quant.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove / from the beginning of model scope names to avoid issues in tensorflow\n",
    "for i in quantized_model.graph.initializer:\n",
    "    i.name = i.name[1:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from onnx2keras import onnx_to_keras\n",
    "\n",
    "# Call the converter (input - is the main model input name, can be different for your model)\n",
    "k_model = onnx_to_keras(onnx_model, ['image.1', 'image.5'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from onnx_tf.backend import prepare\n",
    "\n",
    "tf_rep = prepare(quantized_model, strict=False, gen_tensor_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_rep.run(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_rep.export_graph('./assets/keypoint_tf/keypoint_tflite.pb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_model = torch.jit.script(model)\n",
    "traced_script_module_optimized = optimize_for_mobile(script_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traced_script_module_optimized._save_for_lite_interpreter(\"assets/keypoint_model/model_2.ptl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.jit.save(traced_script_module_optimized, \"assets/keypoint_model/android_model.ptl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4d32610e65d0ba547d20b5ddccd11b31c7d91644470808fb362c82b58c120951"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
